KUBERNETES 1.27
CONTAINERD 1.6.16
UBUNTU 22.04





### ALL: 

sudo -s

hostnamectl set-hostname "k8s-master"
hostnamectl set-hostname "k8s-worker"
printf "\n192.168.1.111 k8s-master k8s-master1\n192.168.1.112 k8s-worker k8s-worker1\n\n" >> /etc/hosts
sudo apt-get update
sudo apt-get install openssh-server -y
sudo service ssh restart 

https://kubernetes.io/fr/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

swapoff -a
lsmod | grep br_netfilter
modprobe br_netfilter
lsmod | grep br_netfilter

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

sudo sysctl --system
ufw status
ufw disable

----------Installation Docker----------------------------------------------------------------------------
apt-get update -y
apt-get install -y docker.io
systemctl start docker
systemctl enable docker

--------------------------------------------------------------------------------------------------------------------------------
### Installing kubeadm, kubelet and kubectl
### https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl
-------------------------------------------------------------------------------------------------------------------------------

sudo apt-get update && sudo apt-get install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

systemctl start kubelet
systemctl enable kubelet
systemctl status kubelet


https://kubernetes.io/fr/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/
### ONLY ON CONTROL NODE .. control plane install:

kubeadm init --pod-network-cidr=192.168.0.0/16 --apiserver-advertise-address=192.168.1.111

To start using your cluster, you need to run the following as a regular user:
  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config
kubectl get node
### ONLY ON  worker
kubeadm join 192.168.1.111:6443 --token oea1n0.gl3kg1bviphm577l \
        --discovery-token-ca-cert-hash sha256:07ae1d1785c557a812e5b14abb79546571d38916b708ef224f84cf7733ae9838

-------------------------------------------------------------------------------------------------------------------------------
# check swap config, ensure swap is 0
free -m

### ONLY ON CONTROL NODE .. control plane install:

kubectl cluster-info
kubectl get node

# get worker node commands to run to join additional nodes into cluster
kubeadm token create --print-join-command

## ONLY ON WORKER nodes
Run the command from the token create output above

----------------------------------------------------------------------------------------------------------------
# add Calico 
https://docs.tigera.io/calico/latest/getting-started/kubernetes/self-managed-onprem/onpremises
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml
curl https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/custom-resources.yaml -O
kubectl create -f custom-resources.yaml



----------------------------------------------------------------------------------------------------------------
on master:
---------
1- check node status : kubectl get nodes
2- API status : curl -k https://localhost:6443/livez?verbose
3- pod status : kubectl get pod -n kube-system
4- container status : ctr -n k8s.io containers list
5- kubectl status : systemctl status kubelet

on worker:
----------
1- container status : ctr -n k8s.io containers list
2- kubectl status : systemctl status kubelet


